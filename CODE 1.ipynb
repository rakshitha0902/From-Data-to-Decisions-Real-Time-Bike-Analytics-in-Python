{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6492734-52c0-40e4-a0fd-8afc069e97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4b1a0-66c7-4213-866c-ef07066a3bf0",
   "metadata": {},
   "source": [
    "### This code saves data in different csv in order to maintain accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db19f28-6f92-4e59-a60a-68e3a69461a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import schedule\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "# API Configuration\n",
    "API_KEY = 'f1cbffee79830f24744dab0edfb64167143f5102'\n",
    "BASE_URL = 'https://api.jcdecaux.com/vls/v3'\n",
    "\n",
    "def fetch_bike_data(contract_name='dublin'):\n",
    "    \"\"\"Fetch bike station data for a specified contract.\"\"\"\n",
    "    url = f\"{BASE_URL}/stations?contract={contract_name}&apiKey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Format lastUpdate to readable format\n",
    "        df['lastUpdate'] = pd.to_datetime(df['lastUpdate'])\n",
    "        df['lastUpdate'] = df['lastUpdate'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Generate a filename with a timestamp to ensure uniqueness\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        filename = f\"Dublin Bikes Dat a_{timestamp}.csv\"\n",
    "        \n",
    "        # Save the dataframe to a CSV file\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Data fetched and saved at {datetime.now()} in file {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "\n",
    "# Set up a schedule to run the data collection every 20 minutes\n",
    "schedule.every(30).minutes.do(fetch_bike_data, contract_name='dublin')\n",
    "\n",
    "# Keep the script running\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5fcde-a510-4998-aa12-715a61cdca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4a915-45af-4326-a535-a1ecf8cfe60d",
   "metadata": {},
   "source": [
    "### All the csv file obtained were combine for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38d18d-0b9f-4c53-9775-bc6e6aed6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_all_csv_files_in_folder(folder_path, output_file):\n",
    "    \"\"\"\n",
    "    Merges all CSV files in a folder into a single DataFrame and saves the result to a file.\n",
    "    :param folder_path: Folder path containing the CSV files\n",
    "    :param output_file: File path to save the merged CSV\n",
    "    \"\"\"\n",
    "    # Get all CSV files from the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found in the directory!\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Found {len(csv_files)} files to merge.\")\n",
    "    \n",
    "    # List to hold DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through and read each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(folder_path, csv_file)\n",
    "        print(f\"Processing: {csv_file}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Merge all DataFrames\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Drop duplicates if necessary\n",
    "    print(f\"Initial rows: {merged_df.shape[0]}\")\n",
    "    merged_df.drop_duplicates(inplace=True)\n",
    "    print(f\"Rows after removing duplicates: {merged_df.shape[0]}\")\n",
    "\n",
    "    # Save merged DataFrame to CSV\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged data saved to: {output_file}\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Specify folder path and output file\n",
    "folder_path = r\"C:\\Users\\raksh\\Dublin_bikes_data\"  # Replace with your folder path\n",
    "output_file = r\"C:\\Users\\raksh\\merged_bike_data1.csv\"  # Replace with desired output file path\n",
    "\n",
    "# Merge all CSV files\n",
    "merged_data = merge_all_csv_files_in_folder(folder_path, output_file)\n",
    "\n",
    "# Display a preview of the merged data\n",
    "if merged_data is not None:\n",
    "    print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf3018-3245-4c1e-bb52-565e1128f98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
